# 个人总结

## 10月总结

10月份第一周、第二周关于具体学到的知识的总结一并放在第三周中，原因是时间统计从10月11号开始试行，前两周处于摸索阶段，不熟悉；

### 10-1周总结

这是第一次使用这种方式记录下自己的时间，在此特别感谢钱老师的无私分享；通过以下几方面总结一下这周的自己：

* 1、使用时间统计带来的直观好处

  * 让我随时都能很清晰的知道现在以前都发生了什么，时间都花在了什么地方，对自己有更清楚的把握（虽然目前这方面感觉还很弱）；
  * 方便自己回顾以前的自己，时间去了哪里，为让自己改进提供了数据基础；
  * 这是试行这种方式的第一周，且也只有5天，所以这只是个开始，但也发现了自己有很多很多需要改进的地方，有很多浪费时间的地方；对于这种方法本身，也还有很多要调整的地方，没有关系，自己要坚持，坚持一种对的方法，坚持去优化去修正，一定会带来意想不到的效果的；

* 2、关于读书

  * 这是一件长久需要坚持需要积累的事情，而且做这件事情要有目的性，要有规划性，而不是漫无目的的去读些书，这样并不会带来有效成长，然后这些弱点正是长久以来伴随着我的；改变固然困难，但不变就绝无未来和希望可言；

  * 这周花了几个小时的时间读了《奇特的一生》，书中讲述了主人公柳比歇夫的奇特一生，它使用自己独创的时间统计法记录、管理规划自己一生的时间，不仅令他可以高效的工作，也保证了自己旺盛的生命力；读了书的前5章，已经感觉到这是一个很值得去学习的人，给我一个很重要的启发是：在时间面前人人平等，找到自己的人生目标，不断寻找并不断优化修正一种正确做事情的方法，坚持去做，坚持下去...对比书中的主人公，我自己还有很长的路要去坚持与修正，对自己以后工作生活的指导是：做有积累的事情、坚持、规划时间、感知时间、记录时间...

* 3、关于一些计划要做而没有做到的事情

  比如自己不止一次的计划要去总结每次听过的《硅谷来信》，真的去花时间去思考那些听的话题，不然听了只是听了，没有对自己产生有效的结果、有效的积累；对于一件事情，不是做了而已，而是做了对自己带来了正向且有效的提升，不然就是花了时间花了精力没有任何收获；而对于是否真的有沉淀和思考的考量是自己能否将思考的东西形成文字，写下来，形成有形的价值表达（及时每天要花1个小时也是值得的，可以慢慢的去缩短这个时间）；

  还比如在学习Python机器学习时，有些很重要的概念计划要去花时间做更深入的分析与思考，以求更深入的理解和运用，最后也是失败告终；

  **归结原因，认为有这几点：**对自己时间把控的能力估计过于乐观，觉着能做完；存在逃避心态，又有点小侥幸，又有点小偷懒，觉着以后会有时间补上；对这件事情本身不够重视，自己虽然有很强的对未知世界的探索欲望，但阶段性的停下来做总结并深入思考是同等重要的；犯了一些拖延症…

以后，对计划本身要更加有把控力，让自己停下来有更多思考和做总结的时间，合理安排好一天的事情（学新知识的时间，总结思考的时间等），慢慢的去发现自己的能力值在哪里，弱点在哪里，去修正他...

最后，这是开始的第一周，只是去试试这种方式，现在做的还比较初级，只是简单的做了些时间记录，以后要慢慢的学会对时间有准确感知，对时间安排有整体规划，让自己更有效率，所以，要更多的思考如何形成自己的一套时间管理与目标规划的方法，适用到自己的工作中去，加油！！！

### 10-3周总结

#### 171024总结

这次总结的主要目的是对前两周的一个回顾，提炼出前两周做的不好的地方，来指导改进后面做事情的方式；

**本次总结的目的：**key point is 对学到的知识作深入的回顾，深度剖析自己这么多天（1011～1023）到底学到了哪些东西，学到了哪个水平；同时，还要看看在哪些地方浪费了时间，哪些地方浪费了无用的时间和精力；let's go ...

**工作和知识列表**

> * 结合python机器学习这本书学习了如下知识点
>   * 机器学习的三种方法（监督、非监督、强化）
>   * 机器学习的蓝图
>     * 数据预处理
>     * 选择预测模型进行训练
>     * 模型验证及使用未知数据进行预测
>   * 机器学习分类算法
>     * 人造神经元的介绍
>     * 使用python实现感知器
>     * Adaline及学习的收敛性：1、使用梯度下降最小化代价函数；2、用python实现Adaline；3、大规模i机器学习和随机梯度下降
>   * 结合sklearn实现机器学习分类算法
>     * 分类算法的选择（只有比较了多种学习算法的性能，才能为特定问题挑选出最合适的模型）
>     * 对sklearn的初步了解（API、数据集、预处理、Pipeline等）
>     * 逻辑回归的类别概率（逻辑回归是什么样的算法；正则化解决过拟合；用sklearn训练逻辑回归；通过逻辑回归的代价函数获得权重）
>     * SVM（使用松弛变量解决非线性问题，sklearn实现svm）
>     * 核SVM解决非线性问题
>     * 决策树（最大化信息增益，随机森林）
>     * k近邻算法
>   * 数据预处理
>     * 缺失值处理，类别数据处理
>     * 数据集分为训练集合测试集（k-fold等）
>     * 特征缩放（归一化和标准化）
>     * 选择特征（使用L1正则满足数据稀疏化，等）
>     * 通过随机森林判断特征重要性
>   * 通过降维压缩数据
>     * 主成分分析PCA降维
>     * 线性判别分析（LDA）压缩无监督数据
>     * 使用主成分分析进行非线性映射
>   * 模型评估与参数调优
>     * 工作流，sklearn中的Pipeline
>     * 使用k-fold交叉验证评估模型性能
>     * 用学习及验证曲线来调试算法
>     * 网格搜索、随机搜索调参数
>     * 不同性能评价指标
>   * 集成学习
> * XGBoost建模
>   * XGBoost原理
>     * 链条：决策树->CART->Boosting（集成学习的一种）->AdaBoost->Gradient Boosting->Boosting Tree->GBDT & GBM->XGBoost
>     * XGBoost优点与性能
>   * sklearn & xgboost的结合使用，做模型训练
>   * XGBoost的超参数与调优过程

**改进方式**

> * 以后做事情要有精益求精的思维，开始可能找不到完美的方式、完美的解决方案，那就先在当时的状态下根据环境做到当时需要的做好，然后在随着环境和需要的变化规划出一个可改进的精进路径，最后一步一步实施路径，最最关键的事情是在实施每一步的时候都要获得正向和反向的反馈，来改良那个可改进的精进路径；这种思维与做事情的前提是当前状态下要有一个清晰的目标，可量化，规定时间内可完成；是否最终的目标也必须是确定的呢？这个应该不需要，我们无法衡量和确定未来是怎样的，但是最终目标是必须要有的，即使是一个模糊不清晰的；



