# 大规模分布式机器学习


## 机器学习简介



## 并行计算

* dask做并行


## 预备资料

* [Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/)

非常详细

* [如何处理机器学习中的不平衡类别](https://github.com/xitu/gold-miner/blob/master/TODO/how-to-handle-imbalanced-classes-in-machine-learning.md)